## 设计理念

这一节简单描述`ZeroNet`对数据和功能边界的界定和设计思路。

总体来看，本框架将跟神经网络所涉及的数据分为四种：流数据、习得参数、网络超参、优化器配置。

基于这样的划分，采用了四层抽象来分别处理这些数据：函数(`function`)-层(`layer`)-网络(`net`)-模型(`model`)。

- 函数负责完成实际的计算过程，不内聚任何数据；
- 层负责包装函数，内聚习得参数，初始化并更新这些习得参数；
- 网络负责处理层与层之间的链接关系（即计算顺序），内聚网络超参（如卷积核大小）、每一层的输入流数据；
- 模型负责整理和提供整个网络的数据分批次输入，优化器的参数配置，管理整个训练和推断的过程。

#### 流数据

流数据是指传入网络的数据和网络前向计算及反向传播时产生的数据，是实际的信息来源。

流数据最初被模型(`model`)整理好，按batch送入网络(`net`)，前向计算时，每一层的输入会被临时记录用于后向传播，到达网络的最后一层，损失函数同时计算损失和反向梯度。

其中，损失传回模型(`model`)用于检测训练状况和模型质量，反向梯度则传回网络，结合临时保存的每层输入计算对习得参数的梯度。

#### 习得参数

习得参数内聚在层(`layer`)这一抽象层次。其维度由层的类别和网络超参共同决定，在如上一段所述的反向传播过程中，习得参数被按照优化器规则更新。

每一个epoch（若干batch）的训练过程结束后，习得参数被传出到模型(`model`)进行存档并在交叉验证集上检验其性能。

#### 网络超参

网络超参是指定义网络结构的参数，比如全连接层(`Linear`)的输出纬度、卷积层(`Conv`)的卷积核大小、步长(stride)等，还包括网络的连接关系、损失函数的选择（以及正则化系数）。

这一部分参数主要在网络(`net`)对象的建立时处理。网络(`net`)对象建立后，需要一个`warmup()`过程来完成网络中习得参数的初始化。

`warmup()`只进行前向计算，用于得到每层网络的输入输出维度，进而初始化合适大小的习得参数。

#### 优化器配置

优化器本身并不内置数据，但在训练过程中，常常要对学习率等进行调整。

这一部分工作由模型(`model`)管理，在训练之初，为优化器初始化配置，并为每个要更新的习得参数保存一份拷贝，并在训练过程中根据训练进度更新这些配置。

